{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#Feature importances\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/datafan07/icr-simple-eda-baseline\n",
    "def balance_logloss(y_true, y_pred):\n",
    "    \n",
    "    y_pred = np.stack([1-y_pred,y_pred]).T\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    y_pred / np.sum(y_pred, axis=1)[:, None]\n",
    "    nc = np.bincount(y_true)\n",
    "    \n",
    "    logloss = (-1/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(y_pred[:,0]))) - 1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred[:,1])))) / 2\n",
    "    \n",
    "    return logloss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"./data/train.csv\")\n",
    "greeks = pd.read_csv(\"./data/greeks.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(raw, greeks, on=\"Id\")\n",
    "df = raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean features\n",
    "def clean_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = df.columns.str.replace(' ', '') # remove spaces\n",
    "    df = df.fillna(df.mean(numeric_only=True))\n",
    "    df[\"EJ\"] = np.where(df[\"EJ\"] == \"A\", 1, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.pipe(clean_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = df.columns[1:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out classes are imbalanced in a ration :4.712962962962963 to 1 \n"
     ]
    }
   ],
   "source": [
    "target = df[\"Class\"]\n",
    "print(f\"Out classes are imbalanced in a ration :{len(target.loc[target == 0])/len(target.loc[target == 1])} to 1 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Fold 1--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's binary_logloss: 0.00874041\tvalid_1's binary_logloss: 0.0728333\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 2--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's binary_logloss: 0.00852636\tvalid_1's binary_logloss: 0.115718\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 3--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[992]\ttraining's binary_logloss: 1.06573e-05\tvalid_1's binary_logloss: 0.0465939\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 4--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's binary_logloss: 0.0689367\tvalid_1's binary_logloss: 0.200273\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 5--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's binary_logloss: 0.000573422\tvalid_1's binary_logloss: 0.0655264\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 6--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's binary_logloss: 0.0378492\tvalid_1's binary_logloss: 0.265117\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 7--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's binary_logloss: 0.0116809\tvalid_1's binary_logloss: 0.14122\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 8--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\ttraining's binary_logloss: 0.021819\tvalid_1's binary_logloss: 0.187589\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 9--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's binary_logloss: 0.0269501\tvalid_1's binary_logloss: 0.257033\n",
      "Evaluated only: binary_logloss\n",
      "--------------------Fold 10--------------------\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's binary_logloss: 0.017654\tvalid_1's binary_logloss: 0.129435\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "simple_folds = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED+FOLDS)\n",
    "oof = np.zeros(len(df))\n",
    "logloss = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(simple_folds.split(df[FEATURES], df[\"Class\"])):\n",
    "    early_stopping_callback = early_stopping(stopping_rounds=300, first_metric_only=True, verbose=True)\n",
    "    print(\"-\"* 20 + f\"Fold {fold+1}\" + \"-\"* 20)\n",
    "    train_dataset = lgb.Dataset(df.loc[train_idx, FEATURES], df.loc[train_idx, \"Class\"], categorical_feature=[\"EJ\"])\n",
    "    eval_dataset  = lgb.Dataset(df.loc[valid_idx, FEATURES], df.loc[valid_idx, \"Class\"], categorical_feature=[\"EJ\"])\n",
    "    lgb_params = {\n",
    "    'objective': 'binary', \n",
    "    'boosting': 'goss',\n",
    "    'learning_rate': 0.0883447499631696,\n",
    "    'num_leaves': 4,\n",
    "    'feature_fraction': 0.5014338346504184,\n",
    "    'bagging_fraction': 0.8486891010640193,\n",
    "    'lambda_l1': 3.264832774300416e-06, \n",
    "    'lambda_l2': 8.605058359426325e-07,\n",
    "    'n_jobs': -1,\n",
    "    'is_unbalance':True, \n",
    "    'verbose': -1,\n",
    "    'seed': SEED,\n",
    "\n",
    "    \n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "                params = lgb_params,\n",
    "                train_set = train_dataset,\n",
    "                num_boost_round = 50000,\n",
    "                valid_sets = [train_dataset, eval_dataset],\n",
    "                callbacks = [early_stopping_callback],\n",
    "                )\n",
    "    \n",
    "    oof[valid_idx] = model.predict(df.loc[valid_idx, FEATURES])\n",
    "    logloss.append(balance_logloss(df.loc[valid_idx, \"Class\"], oof[valid_idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18187420039410832,\n",
       " 0.24744310633008815,\n",
       " 0.03333962055805296,\n",
       " 0.34644534512908953,\n",
       " 0.0779410179690335,\n",
       " 0.3795339352399518,\n",
       " 0.23124057944740933,\n",
       " 0.44983306373935716,\n",
       " 0.3342433645327101,\n",
       " 0.1952212715356735]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_score: 0.2610785714107777\n"
     ]
    }
   ],
   "source": [
    "cv_logloss = balance_logloss(df[\"Class\"].values, oof)\n",
    "print(\"CV_score:\", cv_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(oof, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.pipe(clean_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    for xgb_c in models[bag]:\n",
    "        X_test = test[FEATURES]\n",
    "        predictions += xgb_c.predict_proba(X_test)[:,1]/(BAGS*FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Id\": test[\"Id\"], \"class_0\": 1 - predictions, \"class_1\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
